# Spark SQL / Hive - Chi Ti·∫øt Tri·ªÉn Khai

## üéØ M·ª•c Ti√™u

Ph√¢n t√≠ch batch d·ªØ li·ªáu l·ªãch s·ª≠, ph√°t hi·ªán xu h∆∞·ªõng, v√† t·ªïng h·ª£p d·ªØ li·ªáu ƒë·ªÉ ƒë·∫©y v√†o MySQL Data Mart.

## üìä C√°c B√†i To√°n X·ª≠ L√Ω

### 1. Gi√°m S√°t Vi Ph·∫°m Giao Th√¥ng

#### 1.1. T·ªïng H·ª£p Vi Ph·∫°m Theo Ng√†y/Th√°ng
- **Input**: D·ªØ li·ªáu t·ª´ HDFS Parquet
- **Output**: B·∫£ng t·ªïng h·ª£p theo ng√†y, th√°ng
- **Metrics**:
  - T·ªïng s·ªë vi ph·∫°m theo ng√†y/th√°ng
  - S·ªë vi ph·∫°m theo region
  - S·ªë vi ph·∫°m theo lo·∫°i
  - Top 10 camera c√≥ nhi·ªÅu vi ph·∫°m nh·∫•t
  - T·ª∑ l·ªá tƒÉng/gi·∫£m so v·ªõi k·ª≥ tr∆∞·ªõc

#### 1.2. Ph√¢n T√≠ch Xu H∆∞·ªõng Vi Ph·∫°m
- **Time Series Analysis**:
  - Xu h∆∞·ªõng vi ph·∫°m theo gi·ªù trong ng√†y
  - Xu h∆∞·ªõng vi ph·∫°m theo ng√†y trong tu·∫ßn
  - Xu h∆∞·ªõng vi ph·∫°m theo th√°ng trong nƒÉm
  - Ph√°t hi·ªán seasonal patterns
- **Output**: B·∫£ng time series v·ªõi c√°c metrics

#### 1.3. Ph√¢n T√≠ch Vi Ph·∫°m Theo ƒê·ªãa B√†n
- **Spatial Analysis**:
  - B·∫£n ƒë·ªì nhi·ªát (heatmap) vi ph·∫°m theo region
  - So s√°nh vi ph·∫°m gi·ªØa c√°c region
  - Ph√°t hi·ªán region c√≥ t·ª∑ l·ªá vi ph·∫°m cao
  - Correlation gi·ªØa m·∫≠t ƒë·ªô d√¢n s·ªë v√† vi ph·∫°m (n·∫øu c√≥ d·ªØ li·ªáu)

#### 1.4. Ph√¢n T√≠ch Vi Ph·∫°m Theo Lo·∫°i Ph∆∞∆°ng Ti·ªán
- **Vehicle Analysis**:
  - Ph√¢n b·ªë vi ph·∫°m theo m√†u bi·ªÉn s·ªë (xe c√° nh√¢n vs kinh doanh)
  - Ph√¢n b·ªë vi ph·∫°m theo m√†u xe
  - Top lo·∫°i vi ph·∫°m ph·ªï bi·∫øn nh·∫•t
  - Correlation gi·ªØa lo·∫°i xe v√† lo·∫°i vi ph·∫°m

#### 1.5. Ph√¢n T√≠ch Xe Vi Ph·∫°m Nhi·ªÅu L·∫ßn
- **Repeat Offender Analysis**:
  - X√°c ƒë·ªãnh xe vi ph·∫°m nhi·ªÅu l·∫ßn trong th√°ng
  - Ph√¢n t√≠ch pattern vi ph·∫°m c·ªßa t·ª´ng xe
  - Ph√°t hi·ªán xe c√≥ h√†nh vi vi ph·∫°m nghi√™m tr·ªçng
  - Top 100 xe vi ph·∫°m nhi·ªÅu nh·∫•t

#### 1.6. Ph√¢n T√≠ch Hi·ªáu Qu·∫£ Camera
- **Camera Performance**:
  - S·ªë vi ph·∫°m ph√°t hi·ªán ƒë∆∞·ª£c c·ªßa m·ªói camera
  - So s√°nh hi·ªáu qu·∫£ gi·ªØa c√°c camera
  - Ph√°t hi·ªán camera c√≥ v·∫•n ƒë·ªÅ (qu√° √≠t ho·∫∑c qu√° nhi·ªÅu vi ph·∫°m)
  - ROI c·ªßa t·ª´ng camera

### 2. ƒêo ƒê·∫øm L∆∞u L∆∞·ª£ng Giao Th√¥ng

#### 2.1. T·ªïng H·ª£p L∆∞u L∆∞·ª£ng Theo Th·ªùi Gian
- **Traffic Volume Aggregation**:
  - L∆∞u l∆∞·ª£ng theo gi·ªù/ng√†y/th√°ng
  - L∆∞u l∆∞·ª£ng theo region
  - Peak hours analysis
  - Off-peak hours analysis

#### 2.2. Ph√¢n T√≠ch L∆∞u L∆∞·ª£ng Theo Lo·∫°i Xe
- **Vehicle Type Analysis**:
  - S·ªë l∆∞·ª£ng xe c√° nh√¢n (bi·ªÉn s·ªë ƒëen)
  - S·ªë l∆∞·ª£ng xe kinh doanh (bi·ªÉn s·ªë v√†ng/xanh)
  - T·ª∑ l·ªá % m·ªói lo·∫°i theo th·ªùi gian
  - Xu h∆∞·ªõng thay ƒë·ªïi t·ª∑ l·ªá

#### 2.3. Ph√¢n T√≠ch M·∫≠t ƒê·ªô Giao Th√¥ng
- **Traffic Density**:
  - M·∫≠t ƒë·ªô giao th√¥ng theo gi·ªù
  - M·∫≠t ƒë·ªô theo region
  - So s√°nh v·ªõi capacity c·ªßa ƒë∆∞·ªùng
  - Ph√°t hi·ªán ƒëo·∫°n ƒë∆∞·ªùng qu√° t·∫£i

#### 2.4. Ph√¢n T√≠ch L∆∞u L∆∞·ª£ng Theo Ng√†y Trong Tu·∫ßn
- **Day of Week Analysis**:
  - So s√°nh l∆∞u l∆∞·ª£ng gi·ªØa c√°c ng√†y trong tu·∫ßn
  - Ph√°t hi·ªán ng√†y c√≥ l∆∞u l∆∞·ª£ng cao nh·∫•t/th·∫•p nh·∫•t
  - Pattern theo tu·∫ßn

#### 2.5. D·ª± ƒêo√°n L∆∞u L∆∞·ª£ng
- **Forecasting**:
  - S·ª≠ d·ª•ng Moving Average, Exponential Smoothing
  - D·ª± ƒëo√°n l∆∞u l∆∞·ª£ng cho ng√†y/tu·∫ßn ti·∫øp theo
  - So s√°nh v·ªõi th·ª±c t·∫ø ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c

### 3. T√≠ch H·ª£p C·∫£ Hai

#### 3.1. T·ª∑ L·ªá Vi Ph·∫°m / L∆∞u L∆∞·ª£ng
- **Violation Rate Analysis**:
  - T·ª∑ l·ªá vi ph·∫°m = (S·ªë vi ph·∫°m / T·ªïng l∆∞u l∆∞·ª£ng) √ó 100
  - T·ª∑ l·ªá theo region
  - T·ª∑ l·ªá theo th·ªùi gian
  - Ph√°t hi·ªán region/th·ªùi ƒëi·ªÉm c√≥ t·ª∑ l·ªá vi ph·∫°m cao

#### 3.2. Correlation Analysis
- **Statistical Analysis**:
  - Correlation gi·ªØa l∆∞u l∆∞·ª£ng v√† s·ªë vi ph·∫°m
  - Correlation gi·ªØa th·ªùi gian v√† vi ph·∫°m
  - Correlation gi·ªØa lo·∫°i xe v√† vi ph·∫°m
  - Ph√¢n t√≠ch nguy√™n nh√¢n

#### 3.3. Ph√¢n T√≠ch Hi·ªáu Qu·∫£ Tu·∫ßn Tra
- **Enforcement Effectiveness**:
  - So s√°nh vi ph·∫°m tr∆∞·ªõc v√† sau khi c√≥ tu·∫ßn tra
  - ƒê√°nh gi√° hi·ªáu qu·∫£ c·ªßa camera
  - ROI c·ªßa h·ªá th·ªëng gi√°m s√°t

## üîß Tri·ªÉn Khai Chi Ti·∫øt

### 1. T·∫°o Hive Tables

```sql
-- T·∫°o database
CREATE DATABASE IF NOT EXISTS traffic_violations;

USE traffic_violations;

-- Table cho raw data
CREATE EXTERNAL TABLE IF NOT EXISTS violations_raw (
    camera_id string,
    vin string,
    timestamp bigint,
    timestamp_iso string,
    violation_type int,
    license_plate string,
    video_path string,
    plate_image_path string,
    overview_image_path string,
    vehicle_image_path string,
    before_image_path string,
    additional_image_path string,
    processing_status int,
    violation_severity int,
    vehicle_color string,
    plate_color string,
    region string,
    ingest_timestamp string,
    source_file string
)
PARTITIONED BY (year int, month int, day int)
STORED AS PARQUET
LOCATION '/data/traffic_violations/raw';

-- Repair partitions
MSCK REPAIR TABLE violations_raw;
```

### 2. T·∫°o Views v√† Aggregated Tables

```sql
-- View v·ªõi c√°c c·ªôt t√≠nh to√°n
CREATE VIEW violations_enriched AS
SELECT 
    *,
    from_unixtime(timestamp / 1000) as event_datetime,
    year(from_unixtime(timestamp / 1000)) as event_year,
    month(from_unixtime(timestamp / 1000)) as event_month,
    day(from_unixtime(timestamp / 1000)) as event_day,
    hour(from_unixtime(timestamp / 1000)) as event_hour,
    dayofweek(from_unixtime(timestamp / 1000)) as day_of_week,
    CASE 
        WHEN plate_color = 'black' THEN 'Personal'
        WHEN plate_color IN ('yellow', 'blue') THEN 'Commercial'
        ELSE 'Unknown'
    END as vehicle_category
FROM violations_raw;

-- B·∫£ng t·ªïng h·ª£p theo ng√†y
CREATE TABLE violations_daily_summary AS
SELECT 
    event_date,
    region,
    COUNT(*) as total_violations,
    COUNT(DISTINCT license_plate) as unique_vehicles,
    COUNT(DISTINCT camera_id) as active_cameras,
    COUNT(DISTINCT violation_type) as violation_types,
    SUM(CASE WHEN violation_type = 31 THEN 1 ELSE 0 END) as type_31_count,
    SUM(CASE WHEN violation_type = 61 THEN 1 ELSE 0 END) as type_61_count,
    AVG(violation_severity) as avg_severity,
    COUNT(CASE WHEN vehicle_category = 'Personal' THEN 1 END) as personal_vehicles,
    COUNT(CASE WHEN vehicle_category = 'Commercial' THEN 1 END) as commercial_vehicles
FROM (
    SELECT 
        date(from_unixtime(timestamp / 1000)) as event_date,
        region,
        license_plate,
        camera_id,
        violation_type,
        violation_severity,
        CASE 
            WHEN plate_color = 'black' THEN 'Personal'
            WHEN plate_color IN ('yellow', 'blue') THEN 'Commercial'
            ELSE 'Unknown'
        END as vehicle_category
    FROM violations_raw
) t
GROUP BY event_date, region;
```

### 3. Spark SQL Queries

#### 3.1. Ph√¢n T√≠ch Xu H∆∞·ªõng

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import *

spark = SparkSession.builder \
    .appName("TrafficViolationAnalysis") \
    .enableHiveSupport() \
    .getOrCreate()

# ƒê·ªçc t·ª´ Hive
df = spark.sql("SELECT * FROM traffic_violations.violations_enriched")

# Xu h∆∞·ªõng theo gi·ªù
hourly_trend = df \
    .groupBy("event_hour") \
    .agg(
        count("*").alias("violation_count"),
        countDistinct("license_plate").alias("unique_vehicles"),
        avg("violation_severity").alias("avg_severity")
    ) \
    .orderBy("event_hour")

# Xu h∆∞·ªõng theo ng√†y trong tu·∫ßn
weekly_trend = df \
    .groupBy("day_of_week") \
    .agg(
        count("*").alias("violation_count"),
        countDistinct("license_plate").alias("unique_vehicles")
    ) \
    .orderBy("day_of_week")

# Xu h∆∞·ªõng theo th√°ng
monthly_trend = df \
    .groupBy("event_year", "event_month") \
    .agg(
        count("*").alias("violation_count"),
        countDistinct("license_plate").alias("unique_vehicles"),
        countDistinct("camera_id").alias("active_cameras")
    ) \
    .orderBy("event_year", "event_month")
```

#### 3.2. Ph√¢n T√≠ch Xe Vi Ph·∫°m Nhi·ªÅu L·∫ßn

```python
# Xe vi ph·∫°m nhi·ªÅu l·∫ßn trong th√°ng
repeat_offenders = df \
    .groupBy("license_plate", "event_year", "event_month") \
    .agg(
        count("*").alias("violation_count"),
        collect_set("violation_type").alias("violation_types"),
        collect_set("camera_id").alias("cameras"),
        min("event_datetime").alias("first_violation"),
        max("event_datetime").alias("last_violation")
    ) \
    .filter(col("violation_count") >= 3) \
    .orderBy(desc("violation_count"))

# Top 100 xe vi ph·∫°m nhi·ªÅu nh·∫•t
top_offenders = repeat_offenders \
    .orderBy(desc("violation_count")) \
    .limit(100)
```

#### 3.3. Ph√¢n T√≠ch L∆∞u L∆∞·ª£ng

```python
# L∆∞u l∆∞·ª£ng theo gi·ªù
traffic_volume_hourly = df \
    .groupBy("event_date", "event_hour", "region") \
    .agg(
        countDistinct("license_plate").alias("traffic_volume"),
        count("*").alias("total_records")
    ) \
    .withColumn(
        "violation_rate",
        (col("total_records") / col("traffic_volume")) * 100
    )

# Peak hours
peak_hours = traffic_volume_hourly \
    .groupBy("event_hour") \
    .agg(
        avg("traffic_volume").alias("avg_volume"),
        max("traffic_volume").alias("max_volume")
    ) \
    .orderBy(desc("avg_volume"))
```

#### 3.4. Correlation Analysis

```python
from pyspark.ml.stat import Correlation
from pyspark.ml.feature import VectorAssembler

# T·∫°o features cho correlation
features_df = df \
    .groupBy("event_date", "event_hour", "region") \
    .agg(
        count("*").alias("violation_count"),
        countDistinct("license_plate").alias("traffic_volume"),
        avg("violation_severity").alias("avg_severity")
    ) \
    .withColumn(
        "violation_rate",
        (col("violation_count") / col("traffic_volume")) * 100
    )

# Vectorize
assembler = VectorAssembler(
    inputCols=["violation_count", "traffic_volume", "avg_severity", "violation_rate"],
    outputCol="features"
)

vector_df = assembler.transform(features_df)

# T√≠nh correlation
correlation_matrix = Correlation.corr(vector_df, "features").head()[0]
```

### 4. Ghi V√†o MySQL

```python
# Ghi daily summary v√†o MySQL
daily_summary.write \
    .format("jdbc") \
    .option("url", "jdbc:mysql://localhost:3306/traffic_db") \
    .option("dbtable", "violation_daily_summary") \
    .option("user", "root") \
    .option("password", "password") \
    .mode("overwrite") \
    .save()
```

## üìä Output Tables

### 1. Hive Tables
- `violations_daily_summary`: T·ªïng h·ª£p theo ng√†y
- `violations_monthly_summary`: T·ªïng h·ª£p theo th√°ng
- `violations_by_region`: T·ªïng h·ª£p theo region
- `violations_by_type`: T·ªïng h·ª£p theo lo·∫°i vi ph·∫°m
- `traffic_volume_daily`: L∆∞u l∆∞·ª£ng theo ng√†y
- `traffic_volume_hourly`: L∆∞u l∆∞·ª£ng theo gi·ªù
- `repeat_offenders`: Xe vi ph·∫°m nhi·ªÅu l·∫ßn
- `camera_performance`: Hi·ªáu qu·∫£ camera

### 2. MySQL Tables (s·∫Ω ƒë∆∞·ª£c t·∫°o trong mysql_do.md)
- C√°c b·∫£ng t∆∞∆°ng t·ª± nh∆∞ng t·ªëi ∆∞u cho query nhanh

## üéØ K·∫øt Qu·∫£

- **Batch Analytics**: Ph√¢n t√≠ch d·ªØ li·ªáu l·ªãch s·ª≠
- **Trend Analysis**: Ph√°t hi·ªán xu h∆∞·ªõng
- **Statistical Analysis**: Ph√¢n t√≠ch th·ªëng k√™
- **Data Mart**: D·ªØ li·ªáu t·ªïng h·ª£p s·∫µn cho BI

## üìå T·ª´ Kh√≥a B·∫£o V·ªá

- **OLAP**: Online Analytical Processing
- **Batch Analytics**: Ph√¢n t√≠ch batch
- **Time Series Analysis**: Ph√¢n t√≠ch chu·ªói th·ªùi gian
- **Statistical Analysis**: Ph√¢n t√≠ch th·ªëng k√™
- **Data Mart**: Kho d·ªØ li·ªáu ph√¢n t√≠ch


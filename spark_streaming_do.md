# Spark Streaming - Chi Ti·∫øt Tri·ªÉn Khai

## üéØ M·ª•c Ti√™u

X·ª≠ l√Ω streaming d·ªØ li·ªáu vi ph·∫°m giao th√¥ng v√† l∆∞u l∆∞·ª£ng giao th√¥ng theo th·ªùi gian th·ª±c, ph√°t hi·ªán patterns v√† t√≠nh to√°n metrics.

## üìä C√°c B√†i To√°n X·ª≠ L√Ω

### 1. Gi√°m S√°t Vi Ph·∫°m Giao Th√¥ng

#### 1.1. Th·ªëng K√™ Vi Ph·∫°m Theo Th·ªùi Gian Th·ª±c
- **Window**: 5 ph√∫t, 15 ph√∫t, 1 gi·ªù
- **Metrics**:
  - T·ªïng s·ªë vi ph·∫°m trong window
  - S·ªë vi ph·∫°m theo lo·∫°i (violation_type)
  - S·ªë vi ph·∫°m theo region (camera location)
  - T·ª∑ l·ªá tƒÉng/gi·∫£m so v·ªõi window tr∆∞·ªõc
  - Top 10 camera c√≥ nhi·ªÅu vi ph·∫°m nh·∫•t

#### 1.2. Ph√°t Hi·ªán ƒêi·ªÉm N√≥ng (Hotspot Detection)
- **Window**: 15 ph√∫t, 1 gi·ªù
- **Logic**:
  - T√≠nh s·ªë vi ph·∫°m/gi·ªù cho m·ªói camera
  - So s√°nh v·ªõi ng∆∞·ª°ng trung b√¨nh (mean + 2*std)
  - Alert khi v∆∞·ª£t ng∆∞·ª°ng
- **Output**: Danh s√°ch camera ƒëang ·ªü tr·∫°ng th√°i "hotspot"

#### 1.3. Ph√°t Hi·ªán Vi Ph·∫°m B·∫•t Th∆∞·ªùng
- **Window**: 1 gi·ªù
- **Logic**:
  - So s√°nh s·ªë vi ph·∫°m hi·ªán t·∫°i v·ªõi l·ªãch s·ª≠ c√πng khung gi·ªù
  - Ph√°t hi·ªán spike b·∫•t th∆∞·ªùng (> 3 l·∫ßn trung b√¨nh)
  - Ph√°t hi·ªán drop b·∫•t th∆∞·ªùng (< 0.3 l·∫ßn trung b√¨nh)
- **Use Case**: Ph√°t hi·ªán s·ª± c·ªë camera ho·∫∑c s·ª± ki·ªán ƒë·∫∑c bi·ªát

#### 1.4. Ph√¢n T√≠ch Vi Ph·∫°m Theo Lo·∫°i Ph∆∞∆°ng Ti·ªán
- **Window**: 1 gi·ªù
- **Metrics**:
  - Ph√¢n b·ªë vi ph·∫°m theo lo·∫°i ph∆∞∆°ng ti·ªán (21=√¥ t√¥, 31=xe m√°y, 41=xe ƒë·∫°p, 51=xe kh√°ch, 61=xe t·∫£i)
  - Ph√¢n b·ªë vi ph·∫°m theo m√†u bi·ªÉn s·ªë (xe c√° nh√¢n vs xe kinh doanh)
  - Ph√¢n b·ªë vi ph·∫°m theo m√†u xe
  - Top lo·∫°i vi ph·∫°m (VIN code) ph·ªï bi·∫øn nh·∫•t
  - Correlation gi·ªØa lo·∫°i ph∆∞∆°ng ti·ªán v√† lo·∫°i vi ph·∫°m

#### 1.5. Tracking Xe Vi Ph·∫°m Nhi·ªÅu L·∫ßn
- **Window**: Sliding window 24 gi·ªù
- **Logic**:
  - Group theo bi·ªÉn s·ªë xe
  - ƒê·∫øm s·ªë l·∫ßn vi ph·∫°m trong 24h
  - Alert khi > 3 l·∫ßn vi ph·∫°m
- **Output**: Danh s√°ch xe vi ph·∫°m nhi·ªÅu l·∫ßn

### 2. ƒêo ƒê·∫øm L∆∞u L∆∞·ª£ng Giao Th√¥ng

#### 2.1. T√≠nh L∆∞u L∆∞·ª£ng Theo Th·ªùi Gian
- **Window**: 5 ph√∫t, 15 ph√∫t, 1 gi·ªù
- **Metrics**:
  - S·ªë ph∆∞∆°ng ti·ªán ƒëi qua m·ªói camera (count distinct license_plate)
  - L∆∞u l∆∞·ª£ng theo region
  - L∆∞u l∆∞·ª£ng theo gi·ªù trong ng√†y
  - Peak hours detection

#### 2.2. Ph√¢n T√≠ch L∆∞u L∆∞·ª£ng Theo Lo·∫°i Xe
- **Window**: 1 gi·ªù
- **Metrics**:
  - S·ªë l∆∞·ª£ng xe c√° nh√¢n (bi·ªÉn s·ªë ƒëen)
  - S·ªë l∆∞·ª£ng xe kinh doanh (bi·ªÉn s·ªë v√†ng/xanh)
  - T·ª∑ l·ªá % m·ªói lo·∫°i

#### 2.3. T√≠nh T·ªëc ƒê·ªô Trung B√¨nh (N·∫øu c√≥ d·ªØ li·ªáu)
- **Window**: 15 ph√∫t
- **Logic**:
  - N·∫øu c√≥ timestamp v√† v·ªã tr√≠ camera, t√≠nh t·ªëc ƒë·ªô
  - So s√°nh v·ªõi t·ªëc ƒë·ªô cho ph√©p
  - Ph√°t hi·ªán ƒëo·∫°n ƒë∆∞·ªùng c√≥ t·ªëc ƒë·ªô trung b√¨nh cao

#### 2.4. Ph√¢n T√≠ch M·∫≠t ƒê·ªô Giao Th√¥ng
- **Window**: 15 ph√∫t
- **Metrics**:
  - S·ªë ph∆∞∆°ng ti·ªán/ph√∫t cho m·ªói camera
  - M·∫≠t ƒë·ªô theo region
  - So s√°nh v·ªõi capacity c·ªßa ƒë∆∞·ªùng

#### 2.5. D·ª± ƒêo√°n L∆∞u L∆∞·ª£ng (Simple Moving Average)
- **Window**: 1 gi·ªù
- **Logic**:
  - T√≠nh moving average 3 gi·ªù
  - D·ª± ƒëo√°n l∆∞u l∆∞·ª£ng gi·ªù ti·∫øp theo
  - So s√°nh v·ªõi th·ª±c t·∫ø ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c

### 3. T√≠ch H·ª£p C·∫£ Hai

#### 3.1. T·ª∑ L·ªá Vi Ph·∫°m / L∆∞u L∆∞·ª£ng
- **Window**: 1 gi·ªù
- **Metrics**:
  - T·ª∑ l·ªá vi ph·∫°m = (S·ªë vi ph·∫°m / T·ªïng l∆∞u l∆∞·ª£ng) √ó 100
  - So s√°nh t·ª∑ l·ªá gi·ªØa c√°c region
  - Ph√°t hi·ªán region c√≥ t·ª∑ l·ªá vi ph·∫°m cao b·∫•t th∆∞·ªùng

#### 3.2. Correlation Analysis
- **Window**: 1 gi·ªù
- **Logic**:
  - T√¨m correlation gi·ªØa l∆∞u l∆∞·ª£ng v√† s·ªë vi ph·∫°m
  - Ph√°t hi·ªán khi l∆∞u l∆∞·ª£ng cao nh∆∞ng vi ph·∫°m th·∫•p (c√≥ th·ªÉ do tu·∫ßn tra)
  - Ph√°t hi·ªán khi l∆∞u l∆∞·ª£ng th·∫•p nh∆∞ng vi ph·∫°m cao (c√≥ th·ªÉ do camera nh·∫°y)

## üîß Tri·ªÉn Khai Chi Ti·∫øt

### 1. C·∫•u H√¨nh Spark Streaming

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

# T·∫°o SparkSession
spark = SparkSession.builder \
    .appName("TrafficViolationStreaming") \
    .config("spark.sql.streaming.checkpointLocation", "/checkpoint/traffic") \
    .config("spark.sql.shuffle.partitions", "200") \
    .getOrCreate()

# ƒê·ªçc t·ª´ Kafka
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "traffic_violation_clean") \
    .option("startingOffsets", "latest") \
    .option("failOnDataLoss", "false") \
    .load()
```

### 2. Parse JSON v√† Transform

```python
# Schema cho d·ªØ li·ªáu
schema = StructType([
    StructField("camera_id", StringType()),
    StructField("vin", StringType()),
    StructField("timestamp", LongType()),
    StructField("timestamp_iso", StringType()),
    StructField("violation_type", IntegerType()),
    StructField("license_plate", StringType()),
    StructField("video_path", StringType()),
    StructField("plate_image_path", StringType()),
    StructField("overview_image_path", StringType()),
    StructField("vehicle_image_path", StringType()),
    StructField("before_image_path", StringType()),
    StructField("additional_image_path", StringType()),
    StructField("processing_status", IntegerType()),
    StructField("violation_severity", IntegerType()),
    StructField("vehicle_color", StringType()),
    StructField("plate_color", StringType()),
    StructField("region", StringType()),
    StructField("ingest_timestamp", StringType()),
    StructField("source_file", StringType())
])

# Parse JSON
violations_df = df.select(
    from_json(col("value").cast("string"), schema).alias("data")
).select("data.*")

# Th√™m c·ªôt th·ªùi gian
violations_df = violations_df.withColumn(
    "event_time", 
    from_unixtime(col("timestamp") / 1000)
).withColumn(
    "hour", 
    hour(col("event_time"))
).withColumn(
    "date", 
    to_date(col("event_time"))
)
```

### 3. Window Aggregations

#### 3.1. Th·ªëng K√™ Vi Ph·∫°m 5 Ph√∫t

```python
# Window 5 ph√∫t
window_5min = violations_df \
    .withWatermark("event_time", "10 minutes") \
    .groupBy(
        window(col("event_time"), "5 minutes"),
        col("area_name"),
        col("province"),
        col("vehicle_type"),
        col("vin")
    ) \
    .agg(
        count("*").alias("violation_count"),
        countDistinct("license_plate").alias("unique_vehicles"),
        collect_list("camera_id").alias("cameras")
    )

# Ghi v√†o Kafka
query_5min = window_5min \
    .select(to_json(struct("*")).alias("value")) \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("topic", "traffic_violation_processed") \
    .option("checkpointLocation", "/checkpoint/5min") \
    .start()
```

#### 3.2. Hotspot Detection

```python
# Window 15 ph√∫t ƒë·ªÉ ph√°t hi·ªán hotspot
hotspot_df = violations_df \
    .withWatermark("event_time", "30 minutes") \
    .groupBy(
        window(col("event_time"), "15 minutes"),
        col("camera_id"),
        col("region")
    ) \
    .agg(
        count("*").alias("violation_count")
    ) \
    .withColumn(
        "is_hotspot",
        when(col("violation_count") > 50, True).otherwise(False)
    )

# Alert khi c√≥ hotspot
hotspot_alert = hotspot_df \
    .filter(col("is_hotspot") == True) \
    .select(
        col("window.start").alias("window_start"),
        col("camera_id"),
        col("region"),
        col("violation_count")
    )
```

#### 3.3. L∆∞u L∆∞·ª£ng Giao Th√¥ng

```python
# T√≠nh l∆∞u l∆∞·ª£ng (count distinct license_plate)
traffic_volume = violations_df \
    .withWatermark("event_time", "10 minutes") \
    .groupBy(
        window(col("event_time"), "15 minutes"),
        col("camera_id"),
        col("region")
    ) \
    .agg(
        countDistinct("license_plate").alias("traffic_volume"),
        count("*").alias("total_records")
    ) \
    .withColumn(
        "violation_rate",
        (col("total_records") / col("traffic_volume")) * 100
    )

# Ghi v√†o Kafka topic ri√™ng
query_volume = traffic_volume \
    .select(to_json(struct("*")).alias("value")) \
    .writeStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("topic", "traffic_volume_metrics") \
    .option("checkpointLocation", "/checkpoint/volume") \
    .start()
```

### 4. Ghi V√†o HBase

```python
# Function ƒë·ªÉ ghi v√†o HBase
def write_to_hbase(batch_df, batch_id):
    # Convert DataFrame th√†nh HBase format
    # S·ª≠ d·ª•ng happybase ho·∫∑c hbase-python
    pass

# Ghi v√†o HBase
query_hbase = violations_df \
    .writeStream \
    .foreachBatch(write_to_hbase) \
    .option("checkpointLocation", "/checkpoint/hbase") \
    .start()
```

## üìä Output Streams

### 1. Kafka Topics
- `traffic_violation_processed`: K·∫øt qu·∫£ aggregation
- `traffic_volume_metrics`: Metrics l∆∞u l∆∞·ª£ng
- `traffic_hotspot_alerts`: C·∫£nh b√°o hotspot

### 2. HBase Tables
- `traffic_violations`: Raw data v·ªõi rowkey = `region#timestamp#id`
- `traffic_metrics_5min`: Metrics 5 ph√∫t
- `traffic_metrics_15min`: Metrics 15 ph√∫t
- `traffic_metrics_1hour`: Metrics 1 gi·ªù

### 3. Console/Dashboard
- Real-time metrics hi·ªÉn th·ªã tr√™n console
- C√≥ th·ªÉ t√≠ch h·ª£p v·ªõi Grafana ƒë·ªÉ visualize

## ‚öôÔ∏è C·∫•u H√¨nh Performance

```python
spark.conf.set("spark.sql.streaming.checkpointLocation", "/checkpoint")
spark.conf.set("spark.sql.shuffle.partitions", "200")
spark.conf.set("spark.streaming.backpressure.enabled", "true")
spark.conf.set("spark.streaming.kafka.maxRatePerPartition", "1000")
spark.conf.set("spark.sql.streaming.stateStore.providerClass", 
                "org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider")
```

## üéØ K·∫øt Qu·∫£

- **Real-time Analytics**: X·ª≠ l√Ω d·ªØ li·ªáu g·∫ßn nh∆∞ real-time (latency < 1 ph√∫t)
- **Hotspot Detection**: Ph√°t hi·ªán ƒëi·ªÉm n√≥ng vi ph·∫°m
- **Traffic Volume**: ƒêo ƒë·∫øm l∆∞u l∆∞·ª£ng giao th√¥ng
- **Anomaly Detection**: Ph√°t hi·ªán b·∫•t th∆∞·ªùng
- **Scalability**: C√≥ th·ªÉ scale b·∫±ng c√°ch tƒÉng partitions

## üìå T·ª´ Kh√≥a B·∫£o V·ªá

- **Streaming Analytics**: Ph√¢n t√≠ch d·ªØ li·ªáu streaming
- **Window Aggregation**: T·ªïng h·ª£p theo c·ª≠a s·ªï th·ªùi gian
- **Watermarking**: X·ª≠ l√Ω d·ªØ li·ªáu tr·ªÖ
- **Hotspot Detection**: Ph√°t hi·ªán ƒëi·ªÉm n√≥ng
- **Traffic Volume Analysis**: Ph√¢n t√≠ch l∆∞u l∆∞·ª£ng giao th√¥ng
- **Anomaly Detection**: Ph√°t hi·ªán b·∫•t th∆∞·ªùng

